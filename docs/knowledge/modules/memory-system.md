# MIRIX è®°å¿†ç³»ç»ŸçŸ¥è¯†æ–‡æ¡£

## æ¨¡å—æ¦‚è§ˆ

MIRIXè®°å¿†ç³»ç»Ÿæ˜¯é¡¹ç›®çš„æ ¸å¿ƒåˆ›æ–°ï¼Œå®ç°äº†æ¨¡æ‹Ÿäººç±»è®°å¿†æœºåˆ¶çš„å…­å±‚è®°å¿†æ¶æ„ã€‚ç³»ç»Ÿé€šè¿‡ä¸“é—¨åŒ–çš„è®°å¿†ç®¡ç†å™¨å’Œæ™ºèƒ½åˆ†ç±»æœºåˆ¶ï¼Œå®ç°äº†é«˜æ•ˆçš„è®°å¿†å­˜å‚¨ã€æ£€ç´¢å’Œç®¡ç†åŠŸèƒ½ã€‚

**æ¨¡å—è·¯å¾„**: `mirix/services/` (è®°å¿†ç®¡ç†å™¨), `mirix/orm/` (æ•°æ®æ¨¡å‹)  
**æ ¸å¿ƒæ–‡ä»¶**: `*_memory_manager.py`, `memory.py`, `message.py`  
**ç‰ˆæœ¬**: v0.1.4  

---

## ç¬¬ä¸€å±‚ï¼šæ•´ä½“å¤§çº²

### ğŸ§  è®°å¿†ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ

#### å…­å±‚è®°å¿†æ¨¡å‹
1. **æ ¸å¿ƒè®°å¿†ï¼ˆCore Memoryï¼‰** - ç”¨æˆ·åŸºæœ¬ä¿¡æ¯å’Œä»£ç†äººæ ¼è®¾å®š
2. **æƒ…æ™¯è®°å¿†ï¼ˆEpisodic Memoryï¼‰** - æ—¶é—´åºåˆ—äº‹ä»¶å’Œäº¤äº’å†å²
3. **è¯­ä¹‰è®°å¿†ï¼ˆSemantic Memoryï¼‰** - æ¦‚å¿µæ€§çŸ¥è¯†å’Œäº‹å®ä¿¡æ¯
4. **ç¨‹åºè®°å¿†ï¼ˆProcedural Memoryï¼‰** - æ“ä½œæ­¥éª¤å’ŒæŠ€èƒ½çŸ¥è¯†
5. **èµ„æºè®°å¿†ï¼ˆResource Memoryï¼‰** - å·¥ä½œç©ºé—´å’Œæ–‡ä»¶èµ„æº
6. **çŸ¥è¯†åº“ï¼ˆKnowledge Vaultï¼‰** - ç»“æ„åŒ–çŸ¥è¯†ä½“ç³»

#### è®°å¿†ç³»ç»Ÿæ¶æ„å›¾
```mermaid
graph TB
    subgraph "è¾“å…¥å¤„ç†å±‚"
        A[ç”¨æˆ·è¾“å…¥] --> B[å†…å®¹åˆ†æå™¨]
        B --> C[è®°å¿†åˆ†ç±»å™¨]
    end
    
    subgraph "è®°å¿†ç®¡ç†å±‚"
        C --> D[æ ¸å¿ƒè®°å¿†ç®¡ç†å™¨]
        C --> E[æƒ…æ™¯è®°å¿†ç®¡ç†å™¨]
        C --> F[è¯­ä¹‰è®°å¿†ç®¡ç†å™¨]
        C --> G[ç¨‹åºè®°å¿†ç®¡ç†å™¨]
        C --> H[èµ„æºè®°å¿†ç®¡ç†å™¨]
        C --> I[çŸ¥è¯†åº“ç®¡ç†å™¨]
    end
    
    subgraph "å­˜å‚¨å±‚"
        D --> J[PostgreSQLæ•°æ®åº“]
        E --> J
        F --> J
        G --> J
        H --> J
        I --> J
        
        D --> K[å‘é‡æ•°æ®åº“]
        E --> K
        F --> K
        G --> K
        H --> K
        I --> K
    end
    
    subgraph "æ£€ç´¢å±‚"
        L[æŸ¥è¯¢è¯·æ±‚] --> M[BM25å…¨æ–‡æœç´¢]
        L --> N[å‘é‡ç›¸ä¼¼åº¦æœç´¢]
        M --> O[æ··åˆæœç´¢ç»“æœ]
        N --> O
        O --> P[è®°å¿†æ£€ç´¢ç»“æœ]
    end
```

#### å…³é”®ç‰¹æ€§
- **æ™ºèƒ½åˆ†ç±»**ï¼šè‡ªåŠ¨è¯†åˆ«è¾“å…¥å†…å®¹çš„è®°å¿†ç±»å‹
- **å¤šæ¨¡æ€å­˜å‚¨**ï¼šæ”¯æŒæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ç­‰å¤šç§æ•°æ®ç±»å‹
- **æ··åˆæ£€ç´¢**ï¼šç»“åˆBM25å…¨æ–‡æœç´¢å’Œå‘é‡ç›¸ä¼¼åº¦æœç´¢
- **æ—¶é—´è¡°å‡**ï¼šæ¨¡æ‹Ÿäººç±»è®°å¿†çš„æ—¶é—´è¡°å‡ç‰¹æ€§
- **é‡è¦æ€§è¯„åˆ†**ï¼šæ ¹æ®å†…å®¹é‡è¦æ€§è°ƒæ•´è®°å¿†ä¼˜å…ˆçº§
- **å†²çªè§£å†³**ï¼šå¤„ç†è®°å¿†å†…å®¹çš„å†²çªå’Œæ›´æ–°

---

## ç¬¬äºŒå±‚ï¼šæŠ€æœ¯è®¾è®¡æ”¯æŒ

### ğŸ—ï¸ è®°å¿†æ¶æ„è®¾è®¡åŸåˆ™

#### è®¾è®¡ç†å¿µ
- **åˆ†å±‚å­˜å‚¨**ï¼šä¸åŒç±»å‹è®°å¿†é‡‡ç”¨ä¸åŒçš„å­˜å‚¨ç­–ç•¥
- **æ™ºèƒ½æ£€ç´¢**ï¼šåŸºäºä¸Šä¸‹æ–‡å’Œç›¸å…³æ€§çš„æ™ºèƒ½è®°å¿†æ£€ç´¢
- **åŠ¨æ€ç®¡ç†**ï¼šè®°å¿†çš„è‡ªåŠ¨æ•´ç†ã€å½’æ¡£å’Œæ¸…ç†
- **éšç§ä¿æŠ¤**ï¼šæ‰€æœ‰è®°å¿†æ•°æ®æœ¬åœ°å­˜å‚¨ï¼Œç”¨æˆ·å®Œå…¨æ§åˆ¶

#### æ ¸å¿ƒè®¾è®¡æ¨¡å¼
1. **ç­–ç•¥æ¨¡å¼**ï¼šä¸åŒè®°å¿†ç±»å‹ä½¿ç”¨ä¸åŒçš„å­˜å‚¨å’Œæ£€ç´¢ç­–ç•¥
2. **å·¥å‚æ¨¡å¼**ï¼šåŠ¨æ€åˆ›å»ºè®°å¿†ç®¡ç†å™¨å®ä¾‹
3. **è§‚å¯Ÿè€…æ¨¡å¼**ï¼šè®°å¿†æ›´æ–°æ—¶é€šçŸ¥ç›¸å…³ç»„ä»¶
4. **è£…é¥°å™¨æ¨¡å¼**ï¼šä¸ºè®°å¿†æ“ä½œæ·»åŠ ç¼“å­˜ã€æ—¥å¿—ç­‰åŠŸèƒ½

### ğŸ”§ æŠ€æœ¯é€‰å‹ä¾æ®

#### å­˜å‚¨æŠ€æœ¯é€‰æ‹©
- **PostgreSQL + pgvector**ï¼šä¸»è¦æ•°æ®å­˜å‚¨ï¼Œæ”¯æŒå‘é‡æ“ä½œ
- **Redis**ï¼šç¼“å­˜å±‚ï¼Œæå‡æ£€ç´¢æ€§èƒ½
- **SQLAlchemy ORM**ï¼šæ•°æ®æ¨¡å‹å’ŒæŸ¥è¯¢æŠ½è±¡
- **Pydantic**ï¼šæ•°æ®éªŒè¯å’Œåºåˆ—åŒ–

#### æœç´¢å¼•æ“è®¾è®¡
- **BM25ç®—æ³•**ï¼šåŸºäºè¯é¢‘çš„å…¨æ–‡æœç´¢
- **å‘é‡ç›¸ä¼¼åº¦**ï¼šåŸºäºè¯­ä¹‰çš„ç›¸ä¼¼åº¦æœç´¢
- **æ··åˆæ’åº**ï¼šç»“åˆå¤šç§æœç´¢ç»“æœçš„æ’åºç®—æ³•
- **æŸ¥è¯¢ä¼˜åŒ–**ï¼šç´¢å¼•ä¼˜åŒ–å’ŒæŸ¥è¯¢è®¡åˆ’ä¼˜åŒ–

#### æ€§èƒ½ä¼˜åŒ–ç­–ç•¥
- **åˆ†ç‰‡å­˜å‚¨**ï¼šå¤§å‹è®°å¿†çš„åˆ†ç‰‡å­˜å‚¨å’Œç®¡ç†
- **å¼‚æ­¥å¤„ç†**ï¼šè®°å¿†å­˜å‚¨å’Œç´¢å¼•çš„å¼‚æ­¥å¤„ç†
- **ç¼“å­˜æœºåˆ¶**ï¼šå¤šå±‚ç¼“å­˜æå‡æ£€ç´¢æ€§èƒ½
- **æ‰¹é‡æ“ä½œ**ï¼šæ‰¹é‡è®°å¿†æ“ä½œçš„ä¼˜åŒ–

### ğŸ”— é›†æˆæ–¹æ¡ˆè®¾è®¡

#### ä¸æ™ºèƒ½ä½“ç³»ç»Ÿé›†æˆ
- **è®°å¿†æ£€ç´¢æ¥å£**ï¼šä¸ºæ™ºèƒ½ä½“æä¾›ç»Ÿä¸€çš„è®°å¿†æ£€ç´¢æ¥å£
- **è®°å¿†æ›´æ–°é€šçŸ¥**ï¼šè®°å¿†æ›´æ–°æ—¶é€šçŸ¥ç›¸å…³æ™ºèƒ½ä½“
- **ä¸Šä¸‹æ–‡æ„å»º**ï¼šä¸ºæ™ºèƒ½ä½“æ„å»ºåŒ…å«è®°å¿†çš„ä¸Šä¸‹æ–‡

#### ä¸APIæœåŠ¡é›†æˆ
- **RESTful API**ï¼šæä¾›è®°å¿†ç®¡ç†çš„RESTæ¥å£
- **å®æ—¶é€šä¿¡**ï¼šé€šè¿‡SSEæ¨é€è®°å¿†æ›´æ–°äº‹ä»¶
- **æ‰¹é‡æ“ä½œ**ï¼šæ”¯æŒæ‰¹é‡è®°å¿†æ“ä½œçš„API

---

## ç¬¬ä¸‰å±‚ï¼šå¼€å‘å®æ–½æŒ‡å¯¼

### ğŸš€ æ ¸å¿ƒè®°å¿†ç±»å‹å®ç°

#### 1. æ ¸å¿ƒè®°å¿†ï¼ˆCore Memoryï¼‰
```python
# æ–‡ä»¶ä½ç½®: mirix/services/core_memory_manager.py
class CoreMemoryManager:
    """
    æ ¸å¿ƒè®°å¿†ç®¡ç†å™¨ï¼Œç®¡ç†ç”¨æˆ·åŸºæœ¬ä¿¡æ¯å’Œä»£ç†äººæ ¼è®¾å®š
    
    åŠŸèƒ½ï¼š
    - ç”¨æˆ·ä¸ªäººèµ„æ–™å­˜å‚¨
    - ä»£ç†äººæ ¼è®¾å®šç®¡ç†
    - æ ¸å¿ƒä¿¡æ¯å¿«é€Ÿè®¿é—®
    - ä¿¡æ¯ä¸€è‡´æ€§ç»´æŠ¤
    """
    
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.db_session = get_db_session()
        self.logger = get_logger(__name__)
    
    def update_persona(self, persona_content: str) -> bool:
        """
        æ›´æ–°ä»£ç†äººæ ¼è®¾å®š
        
        Args:
            persona_content: äººæ ¼è®¾å®šå†…å®¹
            
        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            # éªŒè¯å†…å®¹é•¿åº¦
            if len(persona_content) > CORE_MEMORY_PERSONA_CHAR_LIMIT:
                raise ValueError("äººæ ¼è®¾å®šå†…å®¹è¶…å‡ºé•¿åº¦é™åˆ¶")
            
            # æ›´æ–°æ•°æ®åº“è®°å½•
            core_memory = self.db_session.query(CoreMemory).filter_by(
                user_id=self.user_id
            ).first()
            
            if core_memory:
                core_memory.persona = persona_content
                core_memory.updated_at = get_utc_time()
            else:
                core_memory = CoreMemory(
                    user_id=self.user_id,
                    persona=persona_content,
                    created_at=get_utc_time()
                )
                self.db_session.add(core_memory)
            
            self.db_session.commit()
            self.logger.info(f"æ ¸å¿ƒè®°å¿†äººæ ¼è®¾å®šå·²æ›´æ–°: {self.user_id}")
            return True
            
        except Exception as e:
            self.db_session.rollback()
            self.logger.error(f"æ›´æ–°äººæ ¼è®¾å®šå¤±è´¥: {e}")
            return False
    
    def update_human_info(self, human_content: str) -> bool:
        """
        æ›´æ–°ç”¨æˆ·åŸºæœ¬ä¿¡æ¯
        
        Args:
            human_content: ç”¨æˆ·ä¿¡æ¯å†…å®¹
            
        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        # å®ç°ç”¨æˆ·ä¿¡æ¯æ›´æ–°é€»è¾‘
        pass
    
    def get_core_memory(self) -> Dict[str, str]:
        """
        è·å–å®Œæ•´çš„æ ¸å¿ƒè®°å¿†å†…å®¹
        
        Returns:
            Dict[str, str]: åŒ…å«personaå’Œhumançš„æ ¸å¿ƒè®°å¿†
        """
        core_memory = self.db_session.query(CoreMemory).filter_by(
            user_id=self.user_id
        ).first()
        
        if core_memory:
            return {
                "persona": core_memory.persona or DEFAULT_PERSONA,
                "human": core_memory.human or DEFAULT_HUMAN
            }
        else:
            return {
                "persona": DEFAULT_PERSONA,
                "human": DEFAULT_HUMAN
            }
```

#### 2. æƒ…æ™¯è®°å¿†ï¼ˆEpisodic Memoryï¼‰
```python
# æ–‡ä»¶ä½ç½®: mirix/services/episodic_memory_manager.py
class EpisodicMemoryManager:
    """
    æƒ…æ™¯è®°å¿†ç®¡ç†å™¨ï¼Œç®¡ç†æ—¶é—´åºåˆ—ç›¸å…³çš„è®°å¿†
    
    åŠŸèƒ½ï¼š
    - äº‹ä»¶æ—¶é—´æˆ³è®°å½•
    - æ—¶é—´ç›¸å…³æ€§æ£€ç´¢
    - è®°å¿†è¡°å‡ç®¡ç†
    - é‡è¦äº‹ä»¶æ ‡è®°
    """
    
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.db_session = get_db_session()
        self.embedding_model = embedding_model
        self.logger = get_logger(__name__)
    
    def store_episode(self, content: str, timestamp: datetime = None, 
                     importance: float = 1.0, metadata: Dict = None) -> str:
        """
        å­˜å‚¨æƒ…æ™¯è®°å¿†
        
        Args:
            content: è®°å¿†å†…å®¹
            timestamp: æ—¶é—´æˆ³ï¼Œé»˜è®¤ä¸ºå½“å‰æ—¶é—´
            importance: é‡è¦æ€§è¯„åˆ† (0.0-1.0)
            metadata: é™„åŠ å…ƒæ•°æ®
            
        Returns:
            str: è®°å¿†ID
        """
        try:
            if timestamp is None:
                timestamp = get_utc_time()
            
            # ç”Ÿæˆå‘é‡åµŒå…¥
            embedding = self.embedding_model.get_embedding(content)
            
            # åˆ›å»ºæƒ…æ™¯è®°å¿†è®°å½•
            episode = EpisodicMemory(
                id=str(uuid.uuid4()),
                user_id=self.user_id,
                content=content,
                timestamp=timestamp,
                importance=importance,
                embedding=embedding,
                metadata=metadata or {},
                created_at=get_utc_time()
            )
            
            self.db_session.add(episode)
            self.db_session.commit()
            
            self.logger.info(f"æƒ…æ™¯è®°å¿†å·²å­˜å‚¨: {episode.id}")
            return episode.id
            
        except Exception as e:
            self.db_session.rollback()
            self.logger.error(f"å­˜å‚¨æƒ…æ™¯è®°å¿†å¤±è´¥: {e}")
            raise
    
    def retrieve_by_timerange(self, start_time: datetime, end_time: datetime, 
                            limit: int = 10) -> List[EpisodicMemory]:
        """
        æŒ‰æ—¶é—´èŒƒå›´æ£€ç´¢è®°å¿†
        
        Args:
            start_time: å¼€å§‹æ—¶é—´
            end_time: ç»“æŸæ—¶é—´
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            List[EpisodicMemory]: è®°å¿†åˆ—è¡¨
        """
        episodes = self.db_session.query(EpisodicMemory).filter(
            EpisodicMemory.user_id == self.user_id,
            EpisodicMemory.timestamp >= start_time,
            EpisodicMemory.timestamp <= end_time
        ).order_by(
            EpisodicMemory.importance.desc(),
            EpisodicMemory.timestamp.desc()
        ).limit(limit).all()
        
        return episodes
    
    def retrieve_by_similarity(self, query: str, threshold: float = 0.7, 
                             limit: int = 10) -> List[EpisodicMemory]:
        """
        åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢è®°å¿†
        
        Args:
            query: æŸ¥è¯¢å†…å®¹
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            List[EpisodicMemory]: ç›¸ä¼¼è®°å¿†åˆ—è¡¨
        """
        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_embedding = self.embedding_model.get_embedding(query)
        
        # ä½¿ç”¨pgvectorè¿›è¡Œç›¸ä¼¼åº¦æœç´¢
        episodes = self.db_session.query(EpisodicMemory).filter(
            EpisodicMemory.user_id == self.user_id,
            EpisodicMemory.embedding.cosine_distance(query_embedding) < (1 - threshold)
        ).order_by(
            EpisodicMemory.embedding.cosine_distance(query_embedding)
        ).limit(limit).all()
        
        return episodes
    
    def apply_decay(self, decay_factor: float = 0.95):
        """
        åº”ç”¨æ—¶é—´è¡°å‡åˆ°è®°å¿†é‡è¦æ€§
        
        Args:
            decay_factor: è¡°å‡å› å­ (0.0-1.0)
        """
        current_time = get_utc_time()
        
        episodes = self.db_session.query(EpisodicMemory).filter_by(
            user_id=self.user_id
        ).all()
        
        for episode in episodes:
            # è®¡ç®—æ—¶é—´å·®ï¼ˆå¤©æ•°ï¼‰
            time_diff = (current_time - episode.timestamp).days
            
            # åº”ç”¨æŒ‡æ•°è¡°å‡
            new_importance = episode.importance * (decay_factor ** time_diff)
            episode.importance = max(new_importance, 0.01)  # æœ€å°é‡è¦æ€§
        
        self.db_session.commit()
        self.logger.info(f"å·²å¯¹ {len(episodes)} æ¡æƒ…æ™¯è®°å¿†åº”ç”¨æ—¶é—´è¡°å‡")
```

#### 3. è¯­ä¹‰è®°å¿†ï¼ˆSemantic Memoryï¼‰
```python
# æ–‡ä»¶ä½ç½®: mirix/services/semantic_memory_manager.py
class SemanticMemoryManager:
    """
    è¯­ä¹‰è®°å¿†ç®¡ç†å™¨ï¼Œç®¡ç†æ¦‚å¿µæ€§çŸ¥è¯†å’Œäº‹å®ä¿¡æ¯
    
    åŠŸèƒ½ï¼š
    - æ¦‚å¿µå…³ç³»å»ºæ¨¡
    - è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢
    - çŸ¥è¯†å›¾è°±æ„å»º
    - äº‹å®éªŒè¯å’Œæ›´æ–°
    """
    
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.db_session = get_db_session()
        self.embedding_model = embedding_model
        self.logger = get_logger(__name__)
    
    def store_concept(self, concept: str, description: str, 
                     category: str = None, relations: List[str] = None) -> str:
        """
        å­˜å‚¨æ¦‚å¿µè®°å¿†
        
        Args:
            concept: æ¦‚å¿µåç§°
            description: æ¦‚å¿µæè¿°
            category: æ¦‚å¿µåˆ†ç±»
            relations: ç›¸å…³æ¦‚å¿µåˆ—è¡¨
            
        Returns:
            str: æ¦‚å¿µID
        """
        try:
            # ç”Ÿæˆå‘é‡åµŒå…¥
            full_content = f"{concept}: {description}"
            embedding = self.embedding_model.get_embedding(full_content)
            
            # åˆ›å»ºè¯­ä¹‰è®°å¿†è®°å½•
            semantic_memory = SemanticMemory(
                id=str(uuid.uuid4()),
                user_id=self.user_id,
                concept=concept,
                description=description,
                category=category,
                embedding=embedding,
                relations=relations or [],
                created_at=get_utc_time()
            )
            
            self.db_session.add(semantic_memory)
            self.db_session.commit()
            
            self.logger.info(f"è¯­ä¹‰è®°å¿†å·²å­˜å‚¨: {semantic_memory.id}")
            return semantic_memory.id
            
        except Exception as e:
            self.db_session.rollback()
            self.logger.error(f"å­˜å‚¨è¯­ä¹‰è®°å¿†å¤±è´¥: {e}")
            raise
    
    def retrieve_by_concept(self, concept: str) -> List[SemanticMemory]:
        """
        æŒ‰æ¦‚å¿µåç§°æ£€ç´¢è®°å¿†
        
        Args:
            concept: æ¦‚å¿µåç§°
            
        Returns:
            List[SemanticMemory]: ç›¸å…³è®°å¿†åˆ—è¡¨
        """
        memories = self.db_session.query(SemanticMemory).filter(
            SemanticMemory.user_id == self.user_id,
            SemanticMemory.concept.ilike(f"%{concept}%")
        ).all()
        
        return memories
    
    def build_knowledge_graph(self) -> Dict:
        """
        æ„å»ºçŸ¥è¯†å›¾è°±
        
        Returns:
            Dict: çŸ¥è¯†å›¾è°±æ•°æ®ç»“æ„
        """
        memories = self.db_session.query(SemanticMemory).filter_by(
            user_id=self.user_id
        ).all()
        
        # æ„å»ºèŠ‚ç‚¹å’Œè¾¹
        nodes = []
        edges = []
        
        for memory in memories:
            # æ·»åŠ æ¦‚å¿µèŠ‚ç‚¹
            nodes.append({
                "id": memory.id,
                "label": memory.concept,
                "description": memory.description,
                "category": memory.category
            })
            
            # æ·»åŠ å…³ç³»è¾¹
            for relation in memory.relations:
                related_memory = self.db_session.query(SemanticMemory).filter(
                    SemanticMemory.user_id == self.user_id,
                    SemanticMemory.concept == relation
                ).first()
                
                if related_memory:
                    edges.append({
                        "source": memory.id,
                        "target": related_memory.id,
                        "type": "related"
                    })
        
        return {
            "nodes": nodes,
            "edges": edges
        }
```

### ğŸ”§ è®°å¿†æ£€ç´¢å’Œæœç´¢å®ç°

#### æ··åˆæœç´¢å¼•æ“
```python
# æ–‡ä»¶ä½ç½®: mirix/services/memory_search_engine.py
class MemorySearchEngine:
    """
    è®°å¿†æœç´¢å¼•æ“ï¼Œå®ç°BM25å’Œå‘é‡ç›¸ä¼¼åº¦çš„æ··åˆæœç´¢
    
    åŠŸèƒ½ï¼š
    - BM25å…¨æ–‡æœç´¢
    - å‘é‡ç›¸ä¼¼åº¦æœç´¢
    - æ··åˆæœç´¢ç»“æœæ’åº
    - æœç´¢ç»“æœä¼˜åŒ–
    """
    
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.db_session = get_db_session()
        self.embedding_model = embedding_model
        self.bm25_weight = 0.3
        self.vector_weight = 0.7
    
    def hybrid_search(self, query: str, memory_types: List[str] = None, 
                     limit: int = 10) -> List[Dict]:
        """
        æ··åˆæœç´¢è®°å¿†
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            memory_types: è®°å¿†ç±»å‹è¿‡æ»¤
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            List[Dict]: æœç´¢ç»“æœåˆ—è¡¨
        """
        # BM25å…¨æ–‡æœç´¢
        bm25_results = self._bm25_search(query, memory_types, limit * 2)
        
        # å‘é‡ç›¸ä¼¼åº¦æœç´¢
        vector_results = self._vector_search(query, memory_types, limit * 2)
        
        # åˆå¹¶å’Œæ’åºç»“æœ
        combined_results = self._combine_results(bm25_results, vector_results)
        
        # è¿”å›å‰Nä¸ªç»“æœ
        return combined_results[:limit]
    
    def _bm25_search(self, query: str, memory_types: List[str], 
                    limit: int) -> List[Dict]:
        """
        BM25å…¨æ–‡æœç´¢
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            memory_types: è®°å¿†ç±»å‹è¿‡æ»¤
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            List[Dict]: BM25æœç´¢ç»“æœ
        """
        # ä½¿ç”¨PostgreSQLçš„å…¨æ–‡æœç´¢åŠŸèƒ½
        sql_query = """
        SELECT id, content, memory_type, 
               ts_rank(to_tsvector('english', content), plainto_tsquery(%s)) as bm25_score
        FROM memories 
        WHERE user_id = %s 
        AND to_tsvector('english', content) @@ plainto_tsquery(%s)
        """
        
        params = [query, self.user_id, query]
        
        if memory_types:
            sql_query += " AND memory_type = ANY(%s)"
            params.append(memory_types)
        
        sql_query += " ORDER BY bm25_score DESC LIMIT %s"
        params.append(limit)
        
        result = self.db_session.execute(sql_query, params)
        
        return [
            {
                "id": row.id,
                "content": row.content,
                "memory_type": row.memory_type,
                "bm25_score": float(row.bm25_score),
                "vector_score": 0.0
            }
            for row in result
        ]
    
    def _vector_search(self, query: str, memory_types: List[str], 
                      limit: int) -> List[Dict]:
        """
        å‘é‡ç›¸ä¼¼åº¦æœç´¢
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            memory_types: è®°å¿†ç±»å‹è¿‡æ»¤
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            List[Dict]: å‘é‡æœç´¢ç»“æœ
        """
        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_embedding = self.embedding_model.get_embedding(query)
        
        # ä½¿ç”¨pgvectorè¿›è¡Œç›¸ä¼¼åº¦æœç´¢
        sql_query = """
        SELECT id, content, memory_type,
               1 - (embedding <=> %s) as vector_score
        FROM memories 
        WHERE user_id = %s
        """
        
        params = [query_embedding, self.user_id]
        
        if memory_types:
            sql_query += " AND memory_type = ANY(%s)"
            params.append(memory_types)
        
        sql_query += " ORDER BY embedding <=> %s LIMIT %s"
        params.extend([query_embedding, limit])
        
        result = self.db_session.execute(sql_query, params)
        
        return [
            {
                "id": row.id,
                "content": row.content,
                "memory_type": row.memory_type,
                "bm25_score": 0.0,
                "vector_score": float(row.vector_score)
            }
            for row in result
        ]
    
    def _combine_results(self, bm25_results: List[Dict], 
                        vector_results: List[Dict]) -> List[Dict]:
        """
        åˆå¹¶BM25å’Œå‘é‡æœç´¢ç»“æœ
        
        Args:
            bm25_results: BM25æœç´¢ç»“æœ
            vector_results: å‘é‡æœç´¢ç»“æœ
            
        Returns:
            List[Dict]: åˆå¹¶åçš„æœç´¢ç»“æœ
        """
        # åˆ›å»ºç»“æœå­—å…¸ï¼Œä»¥IDä¸ºé”®
        combined = {}
        
        # æ·»åŠ BM25ç»“æœ
        for result in bm25_results:
            combined[result["id"]] = result
        
        # åˆå¹¶å‘é‡ç»“æœ
        for result in vector_results:
            if result["id"] in combined:
                combined[result["id"]]["vector_score"] = result["vector_score"]
            else:
                combined[result["id"]] = result
        
        # è®¡ç®—æ··åˆè¯„åˆ†å¹¶æ’åº
        for result in combined.values():
            result["hybrid_score"] = (
                self.bm25_weight * result["bm25_score"] + 
                self.vector_weight * result["vector_score"]
            )
        
        # æŒ‰æ··åˆè¯„åˆ†æ’åº
        sorted_results = sorted(
            combined.values(), 
            key=lambda x: x["hybrid_score"], 
            reverse=True
        )
        
        return sorted_results
```

### ğŸ” é…ç½®å’Œä½¿ç”¨ç¤ºä¾‹

#### è®°å¿†ç³»ç»Ÿé…ç½®
```yaml
# æ–‡ä»¶ä½ç½®: mirix/configs/memory_config.yaml
memory_system:
  # æ ¸å¿ƒè®°å¿†é…ç½®
  core_memory:
    persona_char_limit: 2000
    human_char_limit: 2000
    
  # æƒ…æ™¯è®°å¿†é…ç½®
  episodic_memory:
    max_entries: 10000
    decay_factor: 0.95
    decay_interval_days: 7
    importance_threshold: 0.1
    
  # è¯­ä¹‰è®°å¿†é…ç½®
  semantic_memory:
    max_entries: 5000
    similarity_threshold: 0.7
    enable_knowledge_graph: true
    
  # ç¨‹åºè®°å¿†é…ç½®
  procedural_memory:
    max_procedures: 1000
    step_limit: 50
    
  # èµ„æºè®°å¿†é…ç½®
  resource_memory:
    max_file_size: 10485760  # 10MB
    supported_formats: ["txt", "pdf", "docx", "md"]
    
  # çŸ¥è¯†åº“é…ç½®
  knowledge_vault:
    max_entries: 2000
    auto_categorize: true
    
  # æœç´¢é…ç½®
  search:
    bm25_weight: 0.3
    vector_weight: 0.7
    max_results: 20
    enable_cache: true
    cache_ttl: 3600  # 1å°æ—¶
```

#### ä½¿ç”¨ç¤ºä¾‹
```python
from mirix.services.episodic_memory_manager import EpisodicMemoryManager
from mirix.services.semantic_memory_manager import SemanticMemoryManager
from mirix.services.memory_search_engine import MemorySearchEngine

# åˆå§‹åŒ–è®°å¿†ç®¡ç†å™¨
user_id = "user_123"
episodic_manager = EpisodicMemoryManager(user_id)
semantic_manager = SemanticMemoryManager(user_id)
search_engine = MemorySearchEngine(user_id)

# å­˜å‚¨æƒ…æ™¯è®°å¿†
episode_id = episodic_manager.store_episode(
    content="ä»Šå¤©å’Œæœ‹å‹ä¸€èµ·å»çœ‹äº†ç”µå½±ã€Šæ˜Ÿé™…ç©¿è¶Šã€‹ï¼Œéå¸¸éœ‡æ’¼",
    importance=0.8,
    metadata={"activity": "entertainment", "location": "cinema"}
)

# å­˜å‚¨è¯­ä¹‰è®°å¿†
concept_id = semantic_manager.store_concept(
    concept="æ˜Ÿé™…ç©¿è¶Š",
    description="å…‹é‡Œæ–¯æ‰˜å¼—Â·è¯ºå…°æ‰§å¯¼çš„ç§‘å¹»ç”µå½±ï¼Œè®²è¿°äº†å®‡å®™æ¢ç´¢å’Œæ—¶é—´æ—…è¡Œçš„æ•…äº‹",
    category="ç”µå½±",
    relations=["ç§‘å¹»ç”µå½±", "å…‹é‡Œæ–¯æ‰˜å¼—Â·è¯ºå…°", "å¤ªç©ºæ¢ç´¢"]
)

# æ··åˆæœç´¢è®°å¿†
search_results = search_engine.hybrid_search(
    query="æ˜Ÿé™…ç©¿è¶Šç”µå½±",
    memory_types=["episodic", "semantic"],
    limit=5
)

for result in search_results:
    print(f"è®°å¿†ID: {result['id']}")
    print(f"å†…å®¹: {result['content']}")
    print(f"ç±»å‹: {result['memory_type']}")
    print(f"æ··åˆè¯„åˆ†: {result['hybrid_score']:.3f}")
    print("---")
```

### ğŸ› å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

#### é—®é¢˜1ï¼šè®°å¿†å­˜å‚¨æ€§èƒ½é—®é¢˜
**ç°è±¡**ï¼šå¤§é‡è®°å¿†å­˜å‚¨æ—¶æ€§èƒ½ä¸‹é™
**åŸå› **ï¼šå‘é‡åµŒå…¥è®¡ç®—å’Œæ•°æ®åº“å†™å…¥çš„æ€§èƒ½ç“¶é¢ˆ
**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# å¯ç”¨æ‰¹é‡å­˜å‚¨
batch_memories = []
for content in memory_contents:
    batch_memories.append({
        "content": content,
        "timestamp": get_utc_time(),
        "importance": 1.0
    })

# æ‰¹é‡å­˜å‚¨è®°å¿†
episodic_manager.batch_store_episodes(batch_memories)

# å¼‚æ­¥å‘é‡åµŒå…¥
import asyncio
async def async_store_episode(content):
    return await episodic_manager.async_store_episode(content)

# å¹¶å‘å¤„ç†
tasks = [async_store_episode(content) for content in contents]
results = await asyncio.gather(*tasks)
```

#### é—®é¢˜2ï¼šè®°å¿†æ£€ç´¢å‡†ç¡®æ€§é—®é¢˜
**ç°è±¡**ï¼šæœç´¢ç»“æœä¸å¤Ÿå‡†ç¡®æˆ–ç›¸å…³æ€§ä½
**åŸå› **ï¼šæœç´¢æƒé‡é…ç½®ä¸å½“æˆ–é˜ˆå€¼è®¾ç½®é—®é¢˜
**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# è°ƒæ•´æœç´¢æƒé‡
search_engine.bm25_weight = 0.4
search_engine.vector_weight = 0.6

# è°ƒæ•´ç›¸ä¼¼åº¦é˜ˆå€¼
semantic_manager.similarity_threshold = 0.8

# å¯ç”¨æŸ¥è¯¢æ‰©å±•
expanded_query = search_engine.expand_query(original_query)
results = search_engine.hybrid_search(expanded_query)
```

#### é—®é¢˜3ï¼šè®°å¿†æ•°æ®ä¸€è‡´æ€§é—®é¢˜
**ç°è±¡**ï¼šè®°å¿†å†…å®¹å‡ºç°å†²çªæˆ–é‡å¤
**åŸå› **ï¼šå¹¶å‘æ›´æ–°æˆ–é‡å¤å­˜å‚¨å¯¼è‡´çš„æ•°æ®ä¸ä¸€è‡´
**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# å¯ç”¨äº‹åŠ¡å¤„ç†
with episodic_manager.db_session.begin():
    # æ£€æŸ¥é‡å¤è®°å¿†
    existing = episodic_manager.find_similar_episodes(content, threshold=0.9)
    if not existing:
        episodic_manager.store_episode(content)
    else:
        # æ›´æ–°ç°æœ‰è®°å¿†
        episodic_manager.update_episode(existing[0].id, content)

# å¯ç”¨è®°å¿†å»é‡
episodic_manager.deduplicate_memories(similarity_threshold=0.95)
```

---

## ğŸ“Š æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–

### å…³é”®æ€§èƒ½æŒ‡æ ‡
- **å­˜å‚¨å»¶è¿Ÿ**ï¼šè®°å¿†å­˜å‚¨æ“ä½œçš„å¹³å‡è€—æ—¶
- **æ£€ç´¢å»¶è¿Ÿ**ï¼šè®°å¿†æ£€ç´¢æ“ä½œçš„å¹³å‡è€—æ—¶
- **å­˜å‚¨ç©ºé—´**ï¼šå„ç±»å‹è®°å¿†å ç”¨çš„å­˜å‚¨ç©ºé—´
- **ç¼“å­˜å‘½ä¸­ç‡**ï¼šè®°å¿†ç¼“å­˜çš„å‘½ä¸­ç‡
- **æœç´¢å‡†ç¡®ç‡**ï¼šæœç´¢ç»“æœçš„ç›¸å…³æ€§è¯„åˆ†

### ä¼˜åŒ–å»ºè®®
1. **ç´¢å¼•ä¼˜åŒ–**ï¼šä¸ºå¸¸ç”¨æŸ¥è¯¢å­—æ®µåˆ›å»ºåˆé€‚çš„ç´¢å¼•
2. **åˆ†åŒºå­˜å‚¨**ï¼šæŒ‰æ—¶é—´æˆ–ç”¨æˆ·å¯¹è®°å¿†æ•°æ®è¿›è¡Œåˆ†åŒº
3. **ç¼“å­˜ç­–ç•¥**ï¼šå®ç°å¤šå±‚ç¼“å­˜æœºåˆ¶
4. **å¼‚æ­¥å¤„ç†**ï¼šå¯¹éå…³é”®æ“ä½œä½¿ç”¨å¼‚æ­¥å¤„ç†
5. **å®šæœŸç»´æŠ¤**ï¼šå®šæœŸæ¸…ç†è¿‡æœŸè®°å¿†å’Œä¼˜åŒ–ç´¢å¼•

---

**æ–‡æ¡£ç‰ˆæœ¬**: v0.1.4  
**æœ€åæ›´æ–°**: 2024å¹´12æœˆ  
**ç»´æŠ¤è€…**: MIRIXå¼€å‘å›¢é˜Ÿ